PYTHONPATH=. python3 online_results/deployment/slurm/launcher.py --user bsc98 --queue acc_bsccs --max-duration 23:59:00 --results-path online_results/output_length/_260/llama-2-7b --default-server-args "{'--enable-chunked-prefill':'', '--disable-log-requests': '', '--model': '/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-2-7b'}" --default-benchmark-args "{'--backend': 'openai', '--disable-tqdm': '', '--dataset-path': '/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/dummy_dataset_mean.json', '--endpoint': '/v1/completions', '--model': '/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-2-7b', '--save-result': '', '--sharegpt-output-len': 260}" --test-server-args "{'--max-num-seqs':['1','2','4','8','16','32','64','128','256','512']}" --test-benchmark-args "{'--num-prompts': ['2000']}"
