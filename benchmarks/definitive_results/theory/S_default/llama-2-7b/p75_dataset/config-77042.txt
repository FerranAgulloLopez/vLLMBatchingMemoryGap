PYTHONPATH=. python3 benchmarks/deployment/slurm/launcher.py --user bsc98 --queue acc_bsccs --max-duration 01:30:00 --results-path benchmarks/definitive_results/theory/S_default/llama-2-7b/p75_dataset --default-server-args "{'--disable-log-requests': '', '--model': '/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-2-7b', '--max-num-seqs': '3000'}" --default-benchmark-args "{'--backend': 'openai', '--disable-tqdm': '', '--dataset-path': '/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/dummy_dataset_p75.json', '--endpoint': '/v1/completions', '--model': '/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-2-7b', '--num-prompts': '3000', '--save-result': ''}" --test-server-args "{'--gpu-memory-utilization': ['0.9', '0.85', '0.8', '0.75', '0.7', '0.65', '0.6', '0.55', '0.5', '0.45', '0.4', '0.35', '0.3', '0.25', '0.2']}" --test-benchmark-args "{}"
