- Create base docker image: `docker build -f Dockerfile -t vllm .`
- Create singularity image with additional requirements to run benchmark: `sudo singularity build vllm-benchmark-default.sif benchmarks/deployment/slurm/SingularityBenchmark.def`
- Schedule different benchmarks e.g., `PYTHONPATH=. python3 benchmarks/lora/deployment/slurm/launcher.py --user bsc98 --queue acc_debug --results-path /home/bsc/bsc098069/llm_benchmarking/results/ --default-server-args "{'--disable-log-stats': '', '--disable-log-requests': '', '--model': '/home/bsc/bsc098069/llm_benchmarking/models/llama/llama-2-7b'}" --default-benchmark-args "{'--disable-log-stats': '', '--backend': 'openai', '--dataset': '/home/bsc/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json', '--endpoint': '/v1/completions', '--model': '/home/bsc/bsc098069/llm_benchmarking/models/llama/llama-2-7b', '--save-result':''}" --test-server-args "{}" --test-benchmark-args "{'--num-prompts': ['10']}"`